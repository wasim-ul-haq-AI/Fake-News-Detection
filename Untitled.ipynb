{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c65ad4a-10cd-4d7e-ae19-7760471d11c3",
   "metadata": {},
   "source": [
    "# 1. Project Title\n",
    "# Fake News Detection Using Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d86f0d6c-b280-40dd-9464-ca0124f55a8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4000, 24)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "df = pd.read_csv(r\"C:\\\\Users\\\\Karachi Laptop\\\\Downloads\\\\fake_news_dataset.csv\", encoding='latin1')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c91f07-eb05-4ec1-b547-11129fe97340",
   "metadata": {},
   "source": [
    "# Remove the useless feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f79f95e6-e060-421f-aed9-6623dbcfb16d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped columns: ['id', 'author', 'date_published', 'char_count', 'source']\n",
      "New shape: (4000, 19)\n"
     ]
    }
   ],
   "source": [
    "cols_to_remove = ['id', 'author', 'date_published', 'char_count', 'source']\n",
    "existing = [c for c in cols_to_remove if c in df.columns]\n",
    "\n",
    "# Drop only the existing ones\n",
    "df = df.drop(existing, axis=1)\n",
    "print(\"Dropped columns:\", existing)\n",
    "print(\"New shape:\", df.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23432036-7d43-4e5e-8edd-770d36fc8a94",
   "metadata": {},
   "source": [
    "# pandas profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d108c2e6-a08a-4f5c-a2b0-ca1fa6cdacfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped columns: ['id', 'author', 'date_published', 'char_count', 'source']\n",
      "New shape: (4000, 19)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Summarize dataset:   0%|                                                      | 0/24 [00:00<?, ?it/s, Describe variable: has_videos]\n",
      "Summarize dataset:  67%|█████████████████████████████████▎                | 16/24 [00:01<00:00, 14.14it/s, Describe variable: label]\u001b[A\n",
      "Summarize dataset:  75%|█████████████████████████████████████▌            | 18/24 [00:01<00:00, 13.12it/s, Describe variable: label]\u001b[A\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████| 19/19 [00:01<00:00, 16.06it/s]\u001b[A\n",
      "Summarize dataset: 100%|███████████████████████████████████████████████████████████████| 109/109 [00:32<00:00,  3.38it/s, Completed]\n",
      "Generate report structure: 100%|██████████████████████████████████████████████████████████████████████| 1/1 [00:14<00:00, 14.20s/it]\n",
      "Render HTML: 100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.16s/it]\n",
      "Export report to file: 100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 18.57it/s]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from ydata_profiling import ProfileReport\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(r\"C:\\\\Users\\\\Karachi Laptop\\\\Downloads\\\\fake_news_dataset.csv\", encoding='latin1')\n",
    "\n",
    "# Drop unnecessary columns\n",
    "cols_to_remove = ['id', 'author', 'date_published', 'char_count', 'source']\n",
    "existing = [c for c in cols_to_remove if c in df.columns]\n",
    "df = df.drop(existing, axis=1)\n",
    "print(\"Dropped columns:\", existing)\n",
    "print(\"New shape:\", df.shape)\n",
    "\n",
    "# Create Pandas Profiling report from the cleaned df\n",
    "profile = ProfileReport(df, title=\"Pandas Profiling Report\", explorative=True)\n",
    "\n",
    "# Save report to HTML\n",
    "profile.to_file(\"report.html\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "165568b8-33b9-4470-991c-de259602333e",
   "metadata": {},
   "source": [
    "# Asking basic question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bcd243c7-9d19-4e2e-b1f1-5741de60debd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4000, 19)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3f9792af-ac6b-4933-8fc4-1d1aa14755f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.info of                    title                                               text  \\\n",
       "0        Breaking News 1  This is the content of article 1. It contains ...   \n",
       "1        Breaking News 2  This is the content of article 2. It contains ...   \n",
       "2        Breaking News 3  This is the content of article 3. It contains ...   \n",
       "3        Breaking News 4  This is the content of article 4. It contains ...   \n",
       "4        Breaking News 5  This is the content of article 5. It contains ...   \n",
       "...                  ...                                                ...   \n",
       "3995  Breaking News 3996  This is the content of article 3996. It contai...   \n",
       "3996  Breaking News 3997  This is the content of article 3997. It contai...   \n",
       "3997  Breaking News 3998  This is the content of article 3998. It contai...   \n",
       "3998  Breaking News 3999  This is the content of article 3999. It contai...   \n",
       "3999  Breaking News 4000  This is the content of article 4000. It contai...   \n",
       "\n",
       "               state       category  sentiment_score  word_count  has_images  \\\n",
       "0          Tennessee  Entertainment            -0.22        1302           0   \n",
       "1          Wisconsin     Technology             0.92         322           1   \n",
       "2           Missouri         Sports             0.25         228           0   \n",
       "3     North Carolina         Sports             0.94         155           1   \n",
       "4         California     Technology            -0.01         962           1   \n",
       "...              ...            ...              ...         ...         ...   \n",
       "3995            Ohio     Technology             0.91        1227           1   \n",
       "3996      Washington         Sports            -0.57        1296           0   \n",
       "3997      California  Entertainment            -0.17         522           0   \n",
       "3998        Illinois         Health            -0.88         169           1   \n",
       "3999           Texas         Health            -0.95         465           0   \n",
       "\n",
       "      has_videos  readability_score  num_shares  num_comments political_bias  \\\n",
       "0              0              66.18       47305           450         Center   \n",
       "1              0              41.10       39804           530           Left   \n",
       "2              1              30.04       45860           763         Center   \n",
       "3              0              75.16       34222           945         Center   \n",
       "4              0              43.90       35934           433          Right   \n",
       "...          ...                ...         ...           ...            ...   \n",
       "3995           1              67.32       38880           697          Right   \n",
       "3996           1              34.86        3650           925           Left   \n",
       "3997           1              48.29       35391           577           Left   \n",
       "3998           0              63.18       40424           201           Left   \n",
       "3999           0              71.24       48913           279          Right   \n",
       "\n",
       "     fact_check_rating  is_satirical  trust_score  source_reputation  \\\n",
       "0                FALSE             1           76                  6   \n",
       "1                Mixed             1            1                  5   \n",
       "2                Mixed             0           57                  1   \n",
       "3                 TRUE             1           18                 10   \n",
       "4                Mixed             0           95                  6   \n",
       "...                ...           ...          ...                ...   \n",
       "3995             Mixed             0           29                 10   \n",
       "3996             FALSE             1           53                  3   \n",
       "3997             FALSE             0           22                  9   \n",
       "3998             FALSE             1            3                  6   \n",
       "3999              TRUE             1           73                  4   \n",
       "\n",
       "      clickbait_score  plagiarism_score label  \n",
       "0                0.84             53.35  Fake  \n",
       "1                0.85             28.28  Fake  \n",
       "2                0.72              0.38  Fake  \n",
       "3                0.92             32.20  Fake  \n",
       "4                0.66             77.70  Real  \n",
       "...               ...               ...   ...  \n",
       "3995             0.22             95.46  Fake  \n",
       "3996             0.42             16.54  Fake  \n",
       "3997             0.50             28.51  Fake  \n",
       "3998             0.17             71.16  Real  \n",
       "3999             0.09             27.65  Real  \n",
       "\n",
       "[4000 rows x 19 columns]>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "865ab37e-86b7-4620-a06e-34fa5cb74972",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>state</th>\n",
       "      <th>category</th>\n",
       "      <th>sentiment_score</th>\n",
       "      <th>word_count</th>\n",
       "      <th>has_images</th>\n",
       "      <th>has_videos</th>\n",
       "      <th>readability_score</th>\n",
       "      <th>num_shares</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>political_bias</th>\n",
       "      <th>fact_check_rating</th>\n",
       "      <th>is_satirical</th>\n",
       "      <th>trust_score</th>\n",
       "      <th>source_reputation</th>\n",
       "      <th>clickbait_score</th>\n",
       "      <th>plagiarism_score</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2533</th>\n",
       "      <td>Breaking News 2534</td>\n",
       "      <td>This is the content of article 2534. It contai...</td>\n",
       "      <td>California</td>\n",
       "      <td>Business</td>\n",
       "      <td>-0.06</td>\n",
       "      <td>1203</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>52.02</td>\n",
       "      <td>5057</td>\n",
       "      <td>763</td>\n",
       "      <td>Left</td>\n",
       "      <td>Mixed</td>\n",
       "      <td>1</td>\n",
       "      <td>72</td>\n",
       "      <td>6</td>\n",
       "      <td>0.67</td>\n",
       "      <td>7.04</td>\n",
       "      <td>Real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2872</th>\n",
       "      <td>Breaking News 2873</td>\n",
       "      <td>This is the content of article 2873. It contai...</td>\n",
       "      <td>Texas</td>\n",
       "      <td>Entertainment</td>\n",
       "      <td>-0.66</td>\n",
       "      <td>788</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>33.02</td>\n",
       "      <td>39754</td>\n",
       "      <td>507</td>\n",
       "      <td>Left</td>\n",
       "      <td>Mixed</td>\n",
       "      <td>1</td>\n",
       "      <td>68</td>\n",
       "      <td>9</td>\n",
       "      <td>1.00</td>\n",
       "      <td>62.39</td>\n",
       "      <td>Fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Breaking News 23</td>\n",
       "      <td>This is the content of article 23. It contains...</td>\n",
       "      <td>New York</td>\n",
       "      <td>Health</td>\n",
       "      <td>0.06</td>\n",
       "      <td>600</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>45.86</td>\n",
       "      <td>24413</td>\n",
       "      <td>73</td>\n",
       "      <td>Left</td>\n",
       "      <td>TRUE</td>\n",
       "      <td>0</td>\n",
       "      <td>94</td>\n",
       "      <td>10</td>\n",
       "      <td>0.74</td>\n",
       "      <td>17.56</td>\n",
       "      <td>Real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3446</th>\n",
       "      <td>Breaking News 3447</td>\n",
       "      <td>This is the content of article 3447. It contai...</td>\n",
       "      <td>Washington</td>\n",
       "      <td>Sports</td>\n",
       "      <td>0.55</td>\n",
       "      <td>987</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>64.74</td>\n",
       "      <td>21289</td>\n",
       "      <td>855</td>\n",
       "      <td>Center</td>\n",
       "      <td>Mixed</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>3</td>\n",
       "      <td>0.55</td>\n",
       "      <td>84.80</td>\n",
       "      <td>Real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1882</th>\n",
       "      <td>Breaking News 1883</td>\n",
       "      <td>This is the content of article 1883. It contai...</td>\n",
       "      <td>Indiana</td>\n",
       "      <td>Health</td>\n",
       "      <td>0.59</td>\n",
       "      <td>610</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>64.52</td>\n",
       "      <td>42289</td>\n",
       "      <td>636</td>\n",
       "      <td>Center</td>\n",
       "      <td>Mixed</td>\n",
       "      <td>1</td>\n",
       "      <td>86</td>\n",
       "      <td>2</td>\n",
       "      <td>0.64</td>\n",
       "      <td>18.87</td>\n",
       "      <td>Fake</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   title                                               text  \\\n",
       "2533  Breaking News 2534  This is the content of article 2534. It contai...   \n",
       "2872  Breaking News 2873  This is the content of article 2873. It contai...   \n",
       "22      Breaking News 23  This is the content of article 23. It contains...   \n",
       "3446  Breaking News 3447  This is the content of article 3447. It contai...   \n",
       "1882  Breaking News 1883  This is the content of article 1883. It contai...   \n",
       "\n",
       "           state       category  sentiment_score  word_count  has_images  \\\n",
       "2533  California       Business            -0.06        1203           1   \n",
       "2872       Texas  Entertainment            -0.66         788           0   \n",
       "22      New York         Health             0.06         600           0   \n",
       "3446  Washington         Sports             0.55         987           1   \n",
       "1882     Indiana         Health             0.59         610           0   \n",
       "\n",
       "      has_videos  readability_score  num_shares  num_comments political_bias  \\\n",
       "2533           1              52.02        5057           763           Left   \n",
       "2872           0              33.02       39754           507           Left   \n",
       "22             0              45.86       24413            73           Left   \n",
       "3446           1              64.74       21289           855         Center   \n",
       "1882           0              64.52       42289           636         Center   \n",
       "\n",
       "     fact_check_rating  is_satirical  trust_score  source_reputation  \\\n",
       "2533             Mixed             1           72                  6   \n",
       "2872             Mixed             1           68                  9   \n",
       "22                TRUE             0           94                 10   \n",
       "3446             Mixed             1           24                  3   \n",
       "1882             Mixed             1           86                  2   \n",
       "\n",
       "      clickbait_score  plagiarism_score label  \n",
       "2533             0.67              7.04  Real  \n",
       "2872             1.00             62.39  Fake  \n",
       "22               0.74             17.56  Real  \n",
       "3446             0.55             84.80  Real  \n",
       "1882             0.64             18.87  Fake  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9ed1c174-f8a9-4707-9574-18c66f4c4b94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title                 object\n",
       "text                  object\n",
       "state                 object\n",
       "category              object\n",
       "sentiment_score      float64\n",
       "word_count             int64\n",
       "has_images             int64\n",
       "has_videos             int64\n",
       "readability_score    float64\n",
       "num_shares             int64\n",
       "num_comments           int64\n",
       "political_bias        object\n",
       "fact_check_rating     object\n",
       "is_satirical           int64\n",
       "trust_score            int64\n",
       "source_reputation      int64\n",
       "clickbait_score      float64\n",
       "plagiarism_score     float64\n",
       "label                 object\n",
       "dtype: object"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b81cc530-0f82-4448-a9d7-803fcffc052b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment_score</th>\n",
       "      <th>word_count</th>\n",
       "      <th>has_images</th>\n",
       "      <th>has_videos</th>\n",
       "      <th>readability_score</th>\n",
       "      <th>num_shares</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>is_satirical</th>\n",
       "      <th>trust_score</th>\n",
       "      <th>source_reputation</th>\n",
       "      <th>clickbait_score</th>\n",
       "      <th>plagiarism_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4000.000000</td>\n",
       "      <td>4000.000000</td>\n",
       "      <td>4000.00000</td>\n",
       "      <td>4000.000000</td>\n",
       "      <td>4000.000000</td>\n",
       "      <td>4000.000000</td>\n",
       "      <td>4000.000000</td>\n",
       "      <td>4000.000000</td>\n",
       "      <td>4000.000000</td>\n",
       "      <td>4000.00000</td>\n",
       "      <td>4000.000000</td>\n",
       "      <td>4000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-0.000645</td>\n",
       "      <td>795.655750</td>\n",
       "      <td>0.49650</td>\n",
       "      <td>0.484500</td>\n",
       "      <td>54.764595</td>\n",
       "      <td>25144.596750</td>\n",
       "      <td>489.870250</td>\n",
       "      <td>0.497000</td>\n",
       "      <td>49.960750</td>\n",
       "      <td>5.54925</td>\n",
       "      <td>0.494447</td>\n",
       "      <td>50.598110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.574768</td>\n",
       "      <td>406.373871</td>\n",
       "      <td>0.50005</td>\n",
       "      <td>0.499822</td>\n",
       "      <td>14.404027</td>\n",
       "      <td>14387.537467</td>\n",
       "      <td>287.435733</td>\n",
       "      <td>0.500054</td>\n",
       "      <td>29.467911</td>\n",
       "      <td>2.87422</td>\n",
       "      <td>0.289138</td>\n",
       "      <td>28.932298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30.020000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.040000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.490000</td>\n",
       "      <td>445.750000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>42.480000</td>\n",
       "      <td>12781.750000</td>\n",
       "      <td>238.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>3.00000</td>\n",
       "      <td>0.240000</td>\n",
       "      <td>25.915000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-0.010000</td>\n",
       "      <td>793.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>54.235000</td>\n",
       "      <td>25308.500000</td>\n",
       "      <td>483.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>6.00000</td>\n",
       "      <td>0.490000</td>\n",
       "      <td>51.480000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.510000</td>\n",
       "      <td>1150.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>67.215000</td>\n",
       "      <td>37453.500000</td>\n",
       "      <td>741.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>8.00000</td>\n",
       "      <td>0.740000</td>\n",
       "      <td>75.580000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1500.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>79.980000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>10.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>99.950000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       sentiment_score   word_count  has_images   has_videos  \\\n",
       "count      4000.000000  4000.000000  4000.00000  4000.000000   \n",
       "mean         -0.000645   795.655750     0.49650     0.484500   \n",
       "std           0.574768   406.373871     0.50005     0.499822   \n",
       "min          -1.000000   100.000000     0.00000     0.000000   \n",
       "25%          -0.490000   445.750000     0.00000     0.000000   \n",
       "50%          -0.010000   793.000000     0.00000     0.000000   \n",
       "75%           0.510000  1150.000000     1.00000     1.000000   \n",
       "max           1.000000  1500.000000     1.00000     1.000000   \n",
       "\n",
       "       readability_score    num_shares  num_comments  is_satirical  \\\n",
       "count        4000.000000   4000.000000   4000.000000   4000.000000   \n",
       "mean           54.764595  25144.596750    489.870250      0.497000   \n",
       "std            14.404027  14387.537467    287.435733      0.500054   \n",
       "min            30.020000     39.000000      0.000000      0.000000   \n",
       "25%            42.480000  12781.750000    238.000000      0.000000   \n",
       "50%            54.235000  25308.500000    483.000000      0.000000   \n",
       "75%            67.215000  37453.500000    741.000000      1.000000   \n",
       "max            79.980000  50000.000000   1000.000000      1.000000   \n",
       "\n",
       "       trust_score  source_reputation  clickbait_score  plagiarism_score  \n",
       "count  4000.000000         4000.00000      4000.000000       4000.000000  \n",
       "mean     49.960750            5.54925         0.494447         50.598110  \n",
       "std      29.467911            2.87422         0.289138         28.932298  \n",
       "min       0.000000            1.00000         0.000000          0.040000  \n",
       "25%      24.000000            3.00000         0.240000         25.915000  \n",
       "50%      50.000000            6.00000         0.490000         51.480000  \n",
       "75%      76.000000            8.00000         0.740000         75.580000  \n",
       "max     100.000000           10.00000         1.000000         99.950000  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4e2f1eda-d425-4ac7-b9f0-46663cd7c72d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1a497aa7-6cb4-407e-9630-872805ae046b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title                0\n",
       "text                 0\n",
       "state                0\n",
       "category             0\n",
       "sentiment_score      0\n",
       "word_count           0\n",
       "has_images           0\n",
       "has_videos           0\n",
       "readability_score    0\n",
       "num_shares           0\n",
       "num_comments         0\n",
       "political_bias       0\n",
       "fact_check_rating    0\n",
       "is_satirical         0\n",
       "trust_score          0\n",
       "source_reputation    0\n",
       "clickbait_score      0\n",
       "plagiarism_score     0\n",
       "label                0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c2326ad-a6ac-40b4-9443-00e8fe73928a",
   "metadata": {},
   "source": [
    "# EDA univariate anlysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f90dfb04-4106-488b-afd5-f1446e06e622",
   "metadata": {},
   "source": [
    "# catogorical data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f419f8fb-45b2-464b-b051-b7bc3065ec58",
   "metadata": {},
   "source": [
    "# counplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "974dfcf3-9842-4593-9ca8-4ec8c532d2a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='count'>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.countplot(['political_bias'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "151ac091-547d-45bf-b6a6-96ddad747d69",
   "metadata": {},
   "source": [
    "# b.pie chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "78347734-8007-4149-befa-dea7b73babe2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='count', ylabel='count'>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts().plot(kind='pie',autopct='%.2f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f53865c8-cd46-4197-bc85-4e723129339c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       76\n",
       "1        1\n",
       "2       57\n",
       "3       18\n",
       "4       95\n",
       "        ..\n",
       "3995    29\n",
       "3996    53\n",
       "3997    22\n",
       "3998     3\n",
       "3999    73\n",
       "Name: trust_score, Length: 4000, dtype: int64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['trust_score']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9308fae-5422-44f7-8804-377d39e2c528",
   "metadata": {},
   "source": [
    "# Numerical data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2283650-bc4a-4f4a-a152-18f6f72bdff5",
   "metadata": {},
   "source": [
    "# histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "486d58e1-1a72-4763-a327-9cab472a3de4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([392., 386., 411., 435., 381., 397., 413., 387., 405., 393.]),\n",
       " array([-1. , -0.8, -0.6, -0.4, -0.2,  0. ,  0.2,  0.4,  0.6,  0.8,  1. ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist(df['sentiment_score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9156c4ec-b207-42c5-9692-bfb51e3c34a3",
   "metadata": {},
   "source": [
    "# Distplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "cd07f75a-e739-4a4b-bf4d-c25532256739",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Karachi Laptop\\AppData\\Local\\Temp\\ipykernel_6364\\749550549.py:1: UserWarning: \n",
      "\n",
      "`distplot` is a deprecated function and will be removed in seaborn v0.14.0.\n",
      "\n",
      "Please adapt your code to use either `displot` (a figure-level function with\n",
      "similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "\n",
      "For a guide to updating your code to use the new functions, please see\n",
      "https://gist.github.com/mwaskom/de44147ed2974457ad6372750bbe5751\n",
      "\n",
      "  sns.distplot(df['readability_score'])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='readability_score', ylabel='count'>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sns.distplot(df['readability_score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdd0bfc6-f58b-40a2-a08c-d3bd32cffbf9",
   "metadata": {},
   "source": [
    "# boxplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "06734c5e-1b1c-4331-b66a-e4d25eeb81d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anconda\\envs\\fakenews_detection\\lib\\site-packages\\seaborn\\categorical.py:379: UserWarning: Attempting to set identical low and high xlims makes transformation singular; automatically expanding.\n",
      "  ax.set_xlim(-.5, n - .5, auto=None)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='readability_score', ylabel='count'>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sns.boxplot(df['trust_score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b45a7b3d-1c40-4f6f-b8fe-4d2e0bf3dc43",
   "metadata": {},
   "source": [
    "# bivariate analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e7194c3-3973-44db-be5d-572d6b6ba0ff",
   "metadata": {},
   "source": [
    "# A.scatterplot(numerical-numerical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4677e915-7de0-41aa-9136-bb5edcdaf39d",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'char_count'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mD:\\anconda\\envs\\fakenews_detection\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3811\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mpandas/_libs/index.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas/_libs/index.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas/_libs/hashtable_class_helper.pxi:7096\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'char_count'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[55], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mseaborn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msns\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m sns\u001b[38;5;241m.\u001b[39mscatterplot(x\u001b[38;5;241m=\u001b[39mdf[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mword_count\u001b[39m\u001b[38;5;124m'\u001b[39m], y\u001b[38;5;241m=\u001b[39m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mchar_count\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[0;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWord Count vs Character Count\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      6\u001b[0m plt\u001b[38;5;241m.\u001b[39mxlabel(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWord Count\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mD:\\anconda\\envs\\fakenews_detection\\lib\\site-packages\\pandas\\core\\frame.py:4113\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4112\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4113\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4114\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4115\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mD:\\anconda\\envs\\fakenews_detection\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3819\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3815\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3816\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3817\u001b[0m     ):\n\u001b[0;32m   3818\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3819\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3820\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3821\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3822\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3823\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3824\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'char_count'"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.scatterplot(x=df['word_count'], y=df['char_count'])\n",
    "plt.title(\"Word Count vs Character Count\")\n",
    "plt.xlabel(\"Word Count\")\n",
    "plt.ylabel(\"Character Count\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c8643b3-d177-4cd5-bc69-ec0ad367c47e",
   "metadata": {},
   "source": [
    "# b.BARplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d22becbc-77fb-4428-b4b0-c8dc6172b529",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.barplot(x='num_comments', y='has_videos', data=df)\n",
    "plt.title(\"Number of Comments vs Has Videos\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "775c4b7d-b5fc-4912-ace3-372cd8eb2cf2",
   "metadata": {},
   "source": [
    "# \n",
    "\n",
    "Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19bd41f0-6a5a-4ae9-8fc8-4f31922babbc",
   "metadata": {},
   "source": [
    "# Remove duplicat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b820512-b379-46ed-9481-c82d242dbe27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicates\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "# Remove rows with null values in 'text' column\n",
    "df = df.dropna(subset=['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f02af48c-3833-49b2-992a-4ca58e5c4e35",
   "metadata": {},
   "source": [
    "# text cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cae0d80-20d9-418e-b646-edb92fd61c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    # Lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove punctuation and special characters\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    \n",
    "    # Remove extra whitespace\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    \n",
    "    return text\n",
    "\n",
    "df['clean_text'] = df['text'].apply(clean_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "273c4561-e307-47dd-87ee-6aea4b3b04a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f3b9273-62e9-4728-a106-64be0f5d9b90",
   "metadata": {},
   "source": [
    "# Text Preprocessing Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e6d11d3-bff3-4246-a5e5-3971688d17d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "df['clean_text'] = df['text'].apply(clean_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a7d3c8-d787-423c-b724-17b46e41a0da",
   "metadata": {},
   "source": [
    "# Tokenization (split text into words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea33f0c-3dd5-4de8-b71b-a528e19d27db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "# Download all nltk datasets (this may take time)\n",
    "nltk.download('all')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0efa2635-eb5d-4e37-ba5b-26e6ee1235ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Download punkt tokenizer (required for word_tokenize)\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Tokenize the text column\n",
    "df['tokens'] = df['clean_text'].apply(word_tokenize)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2348555-d473-414e-8b6a-7f26d16c302c",
   "metadata": {},
   "source": [
    "# Remove Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c200845e-554f-4a19-9bac-ca2df2f53f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "df['tokens'] = df['tokens'].apply(lambda x: [word for word in x if word not in stop_words])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a69f8eba-beb6-4b55-9b15-7001319c4c11",
   "metadata": {},
   "source": [
    "# Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f19455e-3495-4d47-9a4d-a941ab6ecb05",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "nltk.download('wordnet')\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "df['lemmatized'] = df['tokens'].apply(lambda words: [lemmatizer.lemmatize(word) for word in words])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b87740-f31d-44c3-ae8d-7b9cd1e257f6",
   "metadata": {},
   "source": [
    "# Join Tokens Back Into Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e45e18b-8d0e-4e63-a8ec-05da9aaa201c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['final_text'] = df['lemmatized'].apply(lambda x: ' '.join(x))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecaf707f-971b-404b-8e9d-2d68da1851f0",
   "metadata": {},
   "source": [
    "# 12. Convert Text to Numerical Features\n",
    "# Option 1: TF-IDF Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a6840e-4d12-475a-8303-55785da69701",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Import the TF-IDF class\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# 2. Make sure your text column contains strings\n",
    "# If you have tokens, join them first\n",
    "df['final_text'] = df['tokens'].apply(lambda x: ' '.join(x))\n",
    "\n",
    "# 3. Initialize the vectorizer\n",
    "tfidf = TfidfVectorizer(max_features=5000)\n",
    "\n",
    "# 4. Fit and transform your text data\n",
    "X = tfidf.fit_transform(df['final_text']).toarray()\n",
    "\n",
    "# 5. Check the result\n",
    "print(X.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d75271-9cce-4cbd-aee4-514791aaf758",
   "metadata": {},
   "source": [
    "# Option 2: CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa77575-985a-4ed9-9bcc-67e77511537e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer  # Import the class\n",
    "\n",
    "cv = CountVectorizer(max_features=5000)                       # Initialize\n",
    "X = cv.fit_transform(df['final_text']).toarray()             # Fit and transform\n",
    "\n",
    "print(X.shape)  # Optional: check the resulting feature array\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c909bcb-50dc-4d95-96ea-3df5c5d0e424",
   "metadata": {},
   "source": [
    "# Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57654d07-8e46-47da-951e-61b419061580",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming X and y are already defined\n",
    "y = df['label']\n",
    "\n",
    "# Split the dataset into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Optional: check the shapes\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eac0085-f5ca-4751-9a33-86d3713d77e4",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e644937-1692-4d1b-a3ce-e9c7414a6743",
   "metadata": {},
   "source": [
    "# stardaedization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b94c07a-d091-4852-ad9f-057848c5df79",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Use only columns that really exist in your dataset\n",
    "numeric_features = [col for col in [\n",
    "    'word_count',\n",
    "    'char_count',\n",
    "    'sentiment_score',\n",
    "    'readability_score',\n",
    "    'trust_score',\n",
    "    'source_reputation',\n",
    "    'clickbait_score'\n",
    "] if col in df.columns]\n",
    "\n",
    "print(\"Using these numeric features:\", numeric_features)\n",
    "\n",
    "X = df.drop('label', axis=1)\n",
    "y = df['label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit only existing numeric features\n",
    "X_train[numeric_features] = scaler.fit_transform(X_train[numeric_features])\n",
    "\n",
    "# Transform test data\n",
    "X_test[numeric_features] = scaler.transform(X_test[numeric_features])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "481b1490-d352-46d9-bbd3-d8fb8df94946",
   "metadata": {},
   "source": [
    "# Model Training (Logistic Regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51bb935f-ce76-4dda-8d42-491a1a1078bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# ----------------------------\n",
    "# 1. REMOVE TEXT COLUMNS\n",
    "# ----------------------------\n",
    "# Detect numeric columns only\n",
    "numeric_features = df.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "\n",
    "# Remove label from numeric list\n",
    "numeric_features = [col for col in numeric_features if col != 'label']\n",
    "\n",
    "print(\"Using only these numeric features:\", numeric_features)\n",
    "\n",
    "X = df[numeric_features]     # only numeric data\n",
    "y = df['label']\n",
    "\n",
    "# ----------------------------\n",
    "# 2. TRAIN-TEST SPLIT\n",
    "# ----------------------------\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# ----------------------------\n",
    "# 3. STANDARDIZATION\n",
    "# ----------------------------\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# ----------------------------\n",
    "# 4. LOGISTIC REGRESSION MODEL\n",
    "# ----------------------------\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(\"Model trained successfully!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "868d60d7-6e1d-4c77-ba50-72004ecbc641",
   "metadata": {},
   "source": [
    "# Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a250014-8443-4073-bb21-01323b0fbdb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45893156-331f-488a-80ef-feaf043ea165",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2134d4b2-d029-4942-be1b-e69ba59880ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ba32ee3e-a369-4d2d-890b-aa3f3819d5f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "Fake    2026\n",
       "Real    1974\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bc9165b-69e3-4fe8-84e3-f18a02716bca",
   "metadata": {},
   "source": [
    "# Predict on New Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05674662-5931-4d85-bb11-ef0738e7fd1d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
