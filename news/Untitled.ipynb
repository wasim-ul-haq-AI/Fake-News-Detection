{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c65ad4a-10cd-4d7e-ae19-7760471d11c3",
   "metadata": {},
   "source": [
    "# 1. Project Title\n",
    "# Fake News Detection Using Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d86f0d6c-b280-40dd-9464-ca0124f55a8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4000, 24)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "df = pd.read_csv(r\"C:\\\\Users\\\\Karachi Laptop\\\\Downloads\\\\fake_news_dataset.csv\", encoding='latin1')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c91f07-eb05-4ec1-b547-11129fe97340",
   "metadata": {},
   "source": [
    "# Remove the useless feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f79f95e6-e060-421f-aed9-6623dbcfb16d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped columns: ['id', 'author', 'date_published', 'char_count', 'source']\n",
      "New shape: (4000, 19)\n"
     ]
    }
   ],
   "source": [
    "cols_to_remove = ['id', 'author', 'date_published', 'char_count', 'source']\n",
    "existing = [c for c in cols_to_remove if c in df.columns]\n",
    "\n",
    "# Drop only the existing ones\n",
    "df = df.drop(existing, axis=1)\n",
    "print(\"Dropped columns:\", existing)\n",
    "print(\"New shape:\", df.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32909cb8-c07c-4c99-8748-924c30cabbcb",
   "metadata": {},
   "source": [
    "# All column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0fea2fec-c9b5-4bcc-bfb7-cbddf5bd6836",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['title', 'text', 'state', 'category', 'sentiment_score', 'word_count', 'has_images', 'has_videos', 'readability_score', 'num_shares', 'num_comments', 'political_bias', 'fact_check_rating', 'is_satirical', 'trust_score', 'source_reputation', 'clickbait_score', 'plagiarism_score', 'label']\n"
     ]
    }
   ],
   "source": [
    "print(df.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23432036-7d43-4e5e-8edd-770d36fc8a94",
   "metadata": {},
   "source": [
    "# pandas profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d108c2e6-a08a-4f5c-a2b0-ca1fa6cdacfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anconda\\envs\\fakenews_detection\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped columns: ['id', 'author', 'date_published', 'char_count', 'source']\n",
      "New shape: (4000, 19)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Summarize dataset:   0%|                                                      | 0/24 [00:00<?, ?it/s, Describe variable: has_videos]\n",
      "Summarize dataset:  21%|████████▏                              | 5/24 [00:00<00:01, 11.15it/s, Describe variable: fact_check_rating]\u001b[A\n",
      "Summarize dataset:  50%|█████████████████████████                         | 12/24 [00:00<00:01, 11.66it/s, Describe variable: label]\u001b[A\n",
      "Summarize dataset:  71%|███████████████████████████████████▍              | 17/24 [00:00<00:00, 19.11it/s, Describe variable: label]\u001b[A\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████| 19/19 [00:00<00:00, 32.55it/s]\u001b[A\n",
      "Summarize dataset: 100%|███████████████████████████████████████████████████████████████| 109/109 [00:16<00:00,  6.67it/s, Completed]\n",
      "Generate report structure: 100%|██████████████████████████████████████████████████████████████████████| 1/1 [00:07<00:00,  7.68s/it]\n",
      "Render HTML: 100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.23s/it]\n",
      "Export report to file: 100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 27.19it/s]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from ydata_profiling import ProfileReport\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(r\"C:\\\\Users\\\\Karachi Laptop\\\\Downloads\\\\fake_news_dataset.csv\", encoding='latin1')\n",
    "\n",
    "# Drop unnecessary columns\n",
    "cols_to_remove = ['id', 'author', 'date_published', 'char_count', 'source']\n",
    "existing = [c for c in cols_to_remove if c in df.columns]\n",
    "df = df.drop(existing, axis=1)\n",
    "print(\"Dropped columns:\", existing)\n",
    "print(\"New shape:\", df.shape)\n",
    "\n",
    "# Create Pandas Profiling report from the cleaned df\n",
    "profile = ProfileReport(df, title=\"Pandas Profiling Report\", explorative=True)\n",
    "\n",
    "# Save report to HTML\n",
    "profile.to_file(\"report.html\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "165568b8-33b9-4470-991c-de259602333e",
   "metadata": {},
   "source": [
    "# Asking basic question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bcd243c7-9d19-4e2e-b1f1-5741de60debd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4000, 19)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3f9792af-ac6b-4933-8fc4-1d1aa14755f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.info of                    title                                               text  \\\n",
       "0        Breaking News 1  This is the content of article 1. It contains ...   \n",
       "1        Breaking News 2  This is the content of article 2. It contains ...   \n",
       "2        Breaking News 3  This is the content of article 3. It contains ...   \n",
       "3        Breaking News 4  This is the content of article 4. It contains ...   \n",
       "4        Breaking News 5  This is the content of article 5. It contains ...   \n",
       "...                  ...                                                ...   \n",
       "3995  Breaking News 3996  This is the content of article 3996. It contai...   \n",
       "3996  Breaking News 3997  This is the content of article 3997. It contai...   \n",
       "3997  Breaking News 3998  This is the content of article 3998. It contai...   \n",
       "3998  Breaking News 3999  This is the content of article 3999. It contai...   \n",
       "3999  Breaking News 4000  This is the content of article 4000. It contai...   \n",
       "\n",
       "               state       category  sentiment_score  word_count  has_images  \\\n",
       "0          Tennessee  Entertainment            -0.22        1302           0   \n",
       "1          Wisconsin     Technology             0.92         322           1   \n",
       "2           Missouri         Sports             0.25         228           0   \n",
       "3     North Carolina         Sports             0.94         155           1   \n",
       "4         California     Technology            -0.01         962           1   \n",
       "...              ...            ...              ...         ...         ...   \n",
       "3995            Ohio     Technology             0.91        1227           1   \n",
       "3996      Washington         Sports            -0.57        1296           0   \n",
       "3997      California  Entertainment            -0.17         522           0   \n",
       "3998        Illinois         Health            -0.88         169           1   \n",
       "3999           Texas         Health            -0.95         465           0   \n",
       "\n",
       "      has_videos  readability_score  num_shares  num_comments political_bias  \\\n",
       "0              0              66.18       47305           450         Center   \n",
       "1              0              41.10       39804           530           Left   \n",
       "2              1              30.04       45860           763         Center   \n",
       "3              0              75.16       34222           945         Center   \n",
       "4              0              43.90       35934           433          Right   \n",
       "...          ...                ...         ...           ...            ...   \n",
       "3995           1              67.32       38880           697          Right   \n",
       "3996           1              34.86        3650           925           Left   \n",
       "3997           1              48.29       35391           577           Left   \n",
       "3998           0              63.18       40424           201           Left   \n",
       "3999           0              71.24       48913           279          Right   \n",
       "\n",
       "     fact_check_rating  is_satirical  trust_score  source_reputation  \\\n",
       "0                FALSE             1           76                  6   \n",
       "1                Mixed             1            1                  5   \n",
       "2                Mixed             0           57                  1   \n",
       "3                 TRUE             1           18                 10   \n",
       "4                Mixed             0           95                  6   \n",
       "...                ...           ...          ...                ...   \n",
       "3995             Mixed             0           29                 10   \n",
       "3996             FALSE             1           53                  3   \n",
       "3997             FALSE             0           22                  9   \n",
       "3998             FALSE             1            3                  6   \n",
       "3999              TRUE             1           73                  4   \n",
       "\n",
       "      clickbait_score  plagiarism_score label  \n",
       "0                0.84             53.35  Fake  \n",
       "1                0.85             28.28  Fake  \n",
       "2                0.72              0.38  Fake  \n",
       "3                0.92             32.20  Fake  \n",
       "4                0.66             77.70  Real  \n",
       "...               ...               ...   ...  \n",
       "3995             0.22             95.46  Fake  \n",
       "3996             0.42             16.54  Fake  \n",
       "3997             0.50             28.51  Fake  \n",
       "3998             0.17             71.16  Real  \n",
       "3999             0.09             27.65  Real  \n",
       "\n",
       "[4000 rows x 19 columns]>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "865ab37e-86b7-4620-a06e-34fa5cb74972",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>state</th>\n",
       "      <th>category</th>\n",
       "      <th>sentiment_score</th>\n",
       "      <th>word_count</th>\n",
       "      <th>has_images</th>\n",
       "      <th>has_videos</th>\n",
       "      <th>readability_score</th>\n",
       "      <th>num_shares</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>political_bias</th>\n",
       "      <th>fact_check_rating</th>\n",
       "      <th>is_satirical</th>\n",
       "      <th>trust_score</th>\n",
       "      <th>source_reputation</th>\n",
       "      <th>clickbait_score</th>\n",
       "      <th>plagiarism_score</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>Breaking News 253</td>\n",
       "      <td>This is the content of article 253. It contain...</td>\n",
       "      <td>Florida</td>\n",
       "      <td>Technology</td>\n",
       "      <td>-0.29</td>\n",
       "      <td>664</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>63.57</td>\n",
       "      <td>33825</td>\n",
       "      <td>38</td>\n",
       "      <td>Right</td>\n",
       "      <td>Mixed</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>0.85</td>\n",
       "      <td>35.79</td>\n",
       "      <td>Fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3651</th>\n",
       "      <td>Breaking News 3652</td>\n",
       "      <td>This is the content of article 3652. It contai...</td>\n",
       "      <td>Florida</td>\n",
       "      <td>Sports</td>\n",
       "      <td>-0.84</td>\n",
       "      <td>1129</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>45.88</td>\n",
       "      <td>41117</td>\n",
       "      <td>404</td>\n",
       "      <td>Center</td>\n",
       "      <td>TRUE</td>\n",
       "      <td>0</td>\n",
       "      <td>79</td>\n",
       "      <td>5</td>\n",
       "      <td>0.92</td>\n",
       "      <td>25.57</td>\n",
       "      <td>Real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Breaking News 43</td>\n",
       "      <td>This is the content of article 43. It contains...</td>\n",
       "      <td>Washington</td>\n",
       "      <td>Business</td>\n",
       "      <td>0.53</td>\n",
       "      <td>141</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>51.59</td>\n",
       "      <td>9006</td>\n",
       "      <td>59</td>\n",
       "      <td>Left</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0.72</td>\n",
       "      <td>37.78</td>\n",
       "      <td>Real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1724</th>\n",
       "      <td>Breaking News 1725</td>\n",
       "      <td>This is the content of article 1725. It contai...</td>\n",
       "      <td>Georgia</td>\n",
       "      <td>Politics</td>\n",
       "      <td>0.01</td>\n",
       "      <td>828</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>43.16</td>\n",
       "      <td>29852</td>\n",
       "      <td>913</td>\n",
       "      <td>Right</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>1</td>\n",
       "      <td>77</td>\n",
       "      <td>2</td>\n",
       "      <td>0.59</td>\n",
       "      <td>24.18</td>\n",
       "      <td>Fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>719</th>\n",
       "      <td>Breaking News 720</td>\n",
       "      <td>This is the content of article 720. It contain...</td>\n",
       "      <td>Ohio</td>\n",
       "      <td>Politics</td>\n",
       "      <td>-0.95</td>\n",
       "      <td>764</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>40.56</td>\n",
       "      <td>19118</td>\n",
       "      <td>795</td>\n",
       "      <td>Left</td>\n",
       "      <td>Mixed</td>\n",
       "      <td>1</td>\n",
       "      <td>62</td>\n",
       "      <td>8</td>\n",
       "      <td>0.01</td>\n",
       "      <td>45.99</td>\n",
       "      <td>Fake</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   title                                               text  \\\n",
       "252    Breaking News 253  This is the content of article 253. It contain...   \n",
       "3651  Breaking News 3652  This is the content of article 3652. It contai...   \n",
       "42      Breaking News 43  This is the content of article 43. It contains...   \n",
       "1724  Breaking News 1725  This is the content of article 1725. It contai...   \n",
       "719    Breaking News 720  This is the content of article 720. It contain...   \n",
       "\n",
       "           state    category  sentiment_score  word_count  has_images  \\\n",
       "252      Florida  Technology            -0.29         664           1   \n",
       "3651     Florida      Sports            -0.84        1129           0   \n",
       "42    Washington    Business             0.53         141           0   \n",
       "1724     Georgia    Politics             0.01         828           0   \n",
       "719         Ohio    Politics            -0.95         764           0   \n",
       "\n",
       "      has_videos  readability_score  num_shares  num_comments political_bias  \\\n",
       "252            1              63.57       33825            38          Right   \n",
       "3651           0              45.88       41117           404         Center   \n",
       "42             1              51.59        9006            59           Left   \n",
       "1724           1              43.16       29852           913          Right   \n",
       "719            1              40.56       19118           795           Left   \n",
       "\n",
       "     fact_check_rating  is_satirical  trust_score  source_reputation  \\\n",
       "252              Mixed             0           15                  2   \n",
       "3651              TRUE             0           79                  5   \n",
       "42               FALSE             1            6                  4   \n",
       "1724             FALSE             1           77                  2   \n",
       "719              Mixed             1           62                  8   \n",
       "\n",
       "      clickbait_score  plagiarism_score label  \n",
       "252              0.85             35.79  Fake  \n",
       "3651             0.92             25.57  Real  \n",
       "42               0.72             37.78  Real  \n",
       "1724             0.59             24.18  Fake  \n",
       "719              0.01             45.99  Fake  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9ed1c174-f8a9-4707-9574-18c66f4c4b94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title                 object\n",
       "text                  object\n",
       "state                 object\n",
       "category              object\n",
       "sentiment_score      float64\n",
       "word_count             int64\n",
       "has_images             int64\n",
       "has_videos             int64\n",
       "readability_score    float64\n",
       "num_shares             int64\n",
       "num_comments           int64\n",
       "political_bias        object\n",
       "fact_check_rating     object\n",
       "is_satirical           int64\n",
       "trust_score            int64\n",
       "source_reputation      int64\n",
       "clickbait_score      float64\n",
       "plagiarism_score     float64\n",
       "label                 object\n",
       "dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d128a22-8791-4c9c-a20b-0b31bd7d3c13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b81cc530-0f82-4448-a9d7-803fcffc052b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment_score</th>\n",
       "      <th>word_count</th>\n",
       "      <th>has_images</th>\n",
       "      <th>has_videos</th>\n",
       "      <th>readability_score</th>\n",
       "      <th>num_shares</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>is_satirical</th>\n",
       "      <th>trust_score</th>\n",
       "      <th>source_reputation</th>\n",
       "      <th>clickbait_score</th>\n",
       "      <th>plagiarism_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4000.000000</td>\n",
       "      <td>4000.000000</td>\n",
       "      <td>4000.00000</td>\n",
       "      <td>4000.000000</td>\n",
       "      <td>4000.000000</td>\n",
       "      <td>4000.000000</td>\n",
       "      <td>4000.000000</td>\n",
       "      <td>4000.000000</td>\n",
       "      <td>4000.000000</td>\n",
       "      <td>4000.00000</td>\n",
       "      <td>4000.000000</td>\n",
       "      <td>4000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-0.000645</td>\n",
       "      <td>795.655750</td>\n",
       "      <td>0.49650</td>\n",
       "      <td>0.484500</td>\n",
       "      <td>54.764595</td>\n",
       "      <td>25144.596750</td>\n",
       "      <td>489.870250</td>\n",
       "      <td>0.497000</td>\n",
       "      <td>49.960750</td>\n",
       "      <td>5.54925</td>\n",
       "      <td>0.494447</td>\n",
       "      <td>50.598110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.574768</td>\n",
       "      <td>406.373871</td>\n",
       "      <td>0.50005</td>\n",
       "      <td>0.499822</td>\n",
       "      <td>14.404027</td>\n",
       "      <td>14387.537467</td>\n",
       "      <td>287.435733</td>\n",
       "      <td>0.500054</td>\n",
       "      <td>29.467911</td>\n",
       "      <td>2.87422</td>\n",
       "      <td>0.289138</td>\n",
       "      <td>28.932298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30.020000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.040000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.490000</td>\n",
       "      <td>445.750000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>42.480000</td>\n",
       "      <td>12781.750000</td>\n",
       "      <td>238.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>3.00000</td>\n",
       "      <td>0.240000</td>\n",
       "      <td>25.915000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-0.010000</td>\n",
       "      <td>793.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>54.235000</td>\n",
       "      <td>25308.500000</td>\n",
       "      <td>483.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>6.00000</td>\n",
       "      <td>0.490000</td>\n",
       "      <td>51.480000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.510000</td>\n",
       "      <td>1150.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>67.215000</td>\n",
       "      <td>37453.500000</td>\n",
       "      <td>741.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>8.00000</td>\n",
       "      <td>0.740000</td>\n",
       "      <td>75.580000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1500.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>79.980000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>10.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>99.950000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       sentiment_score   word_count  has_images   has_videos  \\\n",
       "count      4000.000000  4000.000000  4000.00000  4000.000000   \n",
       "mean         -0.000645   795.655750     0.49650     0.484500   \n",
       "std           0.574768   406.373871     0.50005     0.499822   \n",
       "min          -1.000000   100.000000     0.00000     0.000000   \n",
       "25%          -0.490000   445.750000     0.00000     0.000000   \n",
       "50%          -0.010000   793.000000     0.00000     0.000000   \n",
       "75%           0.510000  1150.000000     1.00000     1.000000   \n",
       "max           1.000000  1500.000000     1.00000     1.000000   \n",
       "\n",
       "       readability_score    num_shares  num_comments  is_satirical  \\\n",
       "count        4000.000000   4000.000000   4000.000000   4000.000000   \n",
       "mean           54.764595  25144.596750    489.870250      0.497000   \n",
       "std            14.404027  14387.537467    287.435733      0.500054   \n",
       "min            30.020000     39.000000      0.000000      0.000000   \n",
       "25%            42.480000  12781.750000    238.000000      0.000000   \n",
       "50%            54.235000  25308.500000    483.000000      0.000000   \n",
       "75%            67.215000  37453.500000    741.000000      1.000000   \n",
       "max            79.980000  50000.000000   1000.000000      1.000000   \n",
       "\n",
       "       trust_score  source_reputation  clickbait_score  plagiarism_score  \n",
       "count  4000.000000         4000.00000      4000.000000       4000.000000  \n",
       "mean     49.960750            5.54925         0.494447         50.598110  \n",
       "std      29.467911            2.87422         0.289138         28.932298  \n",
       "min       0.000000            1.00000         0.000000          0.040000  \n",
       "25%      24.000000            3.00000         0.240000         25.915000  \n",
       "50%      50.000000            6.00000         0.490000         51.480000  \n",
       "75%      76.000000            8.00000         0.740000         75.580000  \n",
       "max     100.000000           10.00000         1.000000         99.950000  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4e2f1eda-d425-4ac7-b9f0-46663cd7c72d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1a497aa7-6cb4-407e-9630-872805ae046b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title                0\n",
       "text                 0\n",
       "state                0\n",
       "category             0\n",
       "sentiment_score      0\n",
       "word_count           0\n",
       "has_images           0\n",
       "has_videos           0\n",
       "readability_score    0\n",
       "num_shares           0\n",
       "num_comments         0\n",
       "political_bias       0\n",
       "fact_check_rating    0\n",
       "is_satirical         0\n",
       "trust_score          0\n",
       "source_reputation    0\n",
       "clickbait_score      0\n",
       "plagiarism_score     0\n",
       "label                0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c2326ad-a6ac-40b4-9443-00e8fe73928a",
   "metadata": {},
   "source": [
    "# EDA univariate anlysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f90dfb04-4106-488b-afd5-f1446e06e622",
   "metadata": {},
   "source": [
    "# catogorical data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f419f8fb-45b2-464b-b051-b7bc3065ec58",
   "metadata": {},
   "source": [
    "# counplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "974dfcf3-9842-4593-9ca8-4ec8c532d2a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='count'>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.countplot(['political_bias'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "151ac091-547d-45bf-b6a6-96ddad747d69",
   "metadata": {},
   "source": [
    "# b.pie chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "78347734-8007-4149-befa-dea7b73babe2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='count', ylabel='count'>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts().plot(kind='pie',autopct='%.2f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f53865c8-cd46-4197-bc85-4e723129339c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       76\n",
       "1        1\n",
       "2       57\n",
       "3       18\n",
       "4       95\n",
       "        ..\n",
       "3995    29\n",
       "3996    53\n",
       "3997    22\n",
       "3998     3\n",
       "3999    73\n",
       "Name: trust_score, Length: 4000, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['trust_score']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9308fae-5422-44f7-8804-377d39e2c528",
   "metadata": {},
   "source": [
    "# Numerical data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2283650-bc4a-4f4a-a152-18f6f72bdff5",
   "metadata": {},
   "source": [
    "# histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "486d58e1-1a72-4763-a327-9cab472a3de4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([392., 386., 411., 435., 381., 397., 413., 387., 405., 393.]),\n",
       " array([-1. , -0.8, -0.6, -0.4, -0.2,  0. ,  0.2,  0.4,  0.6,  0.8,  1. ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist(df['sentiment_score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9156c4ec-b207-42c5-9692-bfb51e3c34a3",
   "metadata": {},
   "source": [
    "# Distplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cd07f75a-e739-4a4b-bf4d-c25532256739",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Karachi Laptop\\AppData\\Local\\Temp\\ipykernel_4812\\749550549.py:1: UserWarning: \n",
      "\n",
      "`distplot` is a deprecated function and will be removed in seaborn v0.14.0.\n",
      "\n",
      "Please adapt your code to use either `displot` (a figure-level function with\n",
      "similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "\n",
      "For a guide to updating your code to use the new functions, please see\n",
      "https://gist.github.com/mwaskom/de44147ed2974457ad6372750bbe5751\n",
      "\n",
      "  sns.distplot(df['readability_score'])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='readability_score', ylabel='count'>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sns.distplot(df['readability_score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdd0bfc6-f58b-40a2-a08c-d3bd32cffbf9",
   "metadata": {},
   "source": [
    "# boxplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "06734c5e-1b1c-4331-b66a-e4d25eeb81d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anconda\\envs\\fakenews_detection\\lib\\site-packages\\seaborn\\categorical.py:379: UserWarning: Attempting to set identical low and high xlims makes transformation singular; automatically expanding.\n",
      "  ax.set_xlim(-.5, n - .5, auto=None)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='readability_score', ylabel='count'>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sns.boxplot(df['trust_score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b45a7b3d-1c40-4f6f-b8fe-4d2e0bf3dc43",
   "metadata": {},
   "source": [
    "# bivariate analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e7194c3-3973-44db-be5d-572d6b6ba0ff",
   "metadata": {},
   "source": [
    "# A.scatterplot(numerical-numerical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4677e915-7de0-41aa-9136-bb5edcdaf39d",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'char_count'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mD:\\anconda\\envs\\fakenews_detection\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3811\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mpandas/_libs/index.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas/_libs/index.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas/_libs/hashtable_class_helper.pxi:7096\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'char_count'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mseaborn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msns\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m sns\u001b[38;5;241m.\u001b[39mscatterplot(x\u001b[38;5;241m=\u001b[39mdf[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mword_count\u001b[39m\u001b[38;5;124m'\u001b[39m], y\u001b[38;5;241m=\u001b[39m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mchar_count\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[0;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWord Count vs Character Count\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      6\u001b[0m plt\u001b[38;5;241m.\u001b[39mxlabel(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWord Count\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mD:\\anconda\\envs\\fakenews_detection\\lib\\site-packages\\pandas\\core\\frame.py:4113\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4112\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4113\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4114\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4115\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mD:\\anconda\\envs\\fakenews_detection\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3819\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3815\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3816\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3817\u001b[0m     ):\n\u001b[0;32m   3818\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3819\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3820\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3821\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3822\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3823\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3824\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'char_count'"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.scatterplot(x=df['word_count'], y=df['char_count'])\n",
    "plt.title(\"Word Count vs Character Count\")\n",
    "plt.xlabel(\"Word Count\")\n",
    "plt.ylabel(\"Character Count\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c8643b3-d177-4cd5-bc69-ec0ad367c47e",
   "metadata": {},
   "source": [
    "# b.BARplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d22becbc-77fb-4428-b4b0-c8dc6172b529",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.barplot(x='num_comments', y='has_videos', data=df)\n",
    "plt.title(\"Number of Comments vs Has Videos\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "775c4b7d-b5fc-4912-ace3-372cd8eb2cf2",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19bd41f0-6a5a-4ae9-8fc8-4f31922babbc",
   "metadata": {},
   "source": [
    "# Remove duplicat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b820512-b379-46ed-9481-c82d242dbe27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicates\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "# Remove rows with null values in 'text' column\n",
    "df = df.dropna(subset=['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f02af48c-3833-49b2-992a-4ca58e5c4e35",
   "metadata": {},
   "source": [
    "# text cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cae0d80-20d9-418e-b646-edb92fd61c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    # Lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove punctuation and special characters\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    \n",
    "    # Remove extra whitespace\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    \n",
    "    return text\n",
    "\n",
    "df['clean_text'] = df['text'].apply(clean_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "273c4561-e307-47dd-87ee-6aea4b3b04a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f3b9273-62e9-4728-a106-64be0f5d9b90",
   "metadata": {},
   "source": [
    "# Text Preprocessing Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e6d11d3-bff3-4246-a5e5-3971688d17d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "df['clean_text'] = df['text'].apply(clean_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a7d3c8-d787-423c-b724-17b46e41a0da",
   "metadata": {},
   "source": [
    "# Tokenization (split text into words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea33f0c-3dd5-4de8-b71b-a528e19d27db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "# Download all nltk datasets (this may take time)\n",
    "nltk.download('all')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0efa2635-eb5d-4e37-ba5b-26e6ee1235ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Download punkt tokenizer (required for word_tokenize)\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Tokenize the text column\n",
    "df['tokens'] = df['clean_text'].apply(word_tokenize)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2348555-d473-414e-8b6a-7f26d16c302c",
   "metadata": {},
   "source": [
    "# Remove Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c200845e-554f-4a19-9bac-ca2df2f53f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "df['tokens'] = df['tokens'].apply(lambda x: [word for word in x if word not in stop_words])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a69f8eba-beb6-4b55-9b15-7001319c4c11",
   "metadata": {},
   "source": [
    "# Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f19455e-3495-4d47-9a4d-a941ab6ecb05",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "nltk.download('wordnet')\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "df['lemmatized'] = df['tokens'].apply(lambda words: [lemmatizer.lemmatize(word) for word in words])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b87740-f31d-44c3-ae8d-7b9cd1e257f6",
   "metadata": {},
   "source": [
    "# Join Tokens Back Into Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e45e18b-8d0e-4e63-a8ec-05da9aaa201c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['final_text'] = df['lemmatized'].apply(lambda x: ' '.join(x))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecaf707f-971b-404b-8e9d-2d68da1851f0",
   "metadata": {},
   "source": [
    "# 12. Convert Text to Numerical Features\n",
    "# Option 1: TF-IDF Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a6840e-4d12-475a-8303-55785da69701",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Import the TF-IDF class\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# 2. Make sure your text column contains strings\n",
    "# If you have tokens, join them first\n",
    "df['final_text'] = df['tokens'].apply(lambda x: ' '.join(x))\n",
    "\n",
    "# 3. Initialize the vectorizer\n",
    "tfidf = TfidfVectorizer(max_features=5000)\n",
    "\n",
    "# 4. Fit and transform your text data\n",
    "X = tfidf.fit_transform(df['final_text']).toarray()\n",
    "\n",
    "# 5. Check the result\n",
    "print(X.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d75271-9cce-4cbd-aee4-514791aaf758",
   "metadata": {},
   "source": [
    "# Option 2: CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa77575-985a-4ed9-9bcc-67e77511537e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer  # Import the class\n",
    "\n",
    "cv = CountVectorizer(max_features=5000)                       # Initialize\n",
    "X = cv.fit_transform(df['final_text']).toarray()             # Fit and transform\n",
    "\n",
    "print(X.shape)  # Optional: check the resulting feature array\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac64355c-108e-466a-9259-68f3fbf9bcb5",
   "metadata": {},
   "source": [
    "# separate column for ordinal encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bd799c6f-99aa-42cc-9a01-ef8e2d4e2bae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ordinal Columns:\n",
      "   source_reputation political_bias  clickbait_score  sentiment_score\n",
      "0                  6         Center             0.84            -0.22\n",
      "1                  5           Left             0.85             0.92\n",
      "2                  1         Center             0.72             0.25\n",
      "3                 10         Center             0.92             0.94\n",
      "4                  6          Right             0.66            -0.01\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load your dataset (example)\n",
    "# df = pd.read_csv(\"your_file.csv\")\n",
    "\n",
    "# Columns that need Ordinal Encoding\n",
    "ordinal_features = [\n",
    "    \"source_reputation\",\n",
    "    \"political_bias\",\n",
    "    \"clickbait_score\",\n",
    "    \"sentiment_score\"\n",
    "]\n",
    "\n",
    "# Select only these columns\n",
    "ordinal_cols = df[ordinal_features]\n",
    "\n",
    "print(\"Ordinal Columns:\")\n",
    "print(ordinal_cols.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2b708c7-0f7e-40c4-b41f-17bb7288449c",
   "metadata": {},
   "source": [
    "# Lable encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4a67ef54-d6d6-4c87-b371-4de76dc0f076",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label encoded values:\n",
      "0    0\n",
      "1    0\n",
      "2    0\n",
      "3    0\n",
      "4    1\n",
      "Name: label, dtype: int64\n",
      "Label mapping: {'Fake': np.int64(0), 'Real': np.int64(1)}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Change this to your actual final column name\n",
    "target_column = \"label\"   # <-- replace if different\n",
    "\n",
    "# Initialize encoder\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Fit + transform your target variable\n",
    "df[target_column] = le.fit_transform(df[target_column])\n",
    "\n",
    "print(\"Label encoded values:\")\n",
    "print(df[target_column].head())\n",
    "\n",
    "# Check mapping (important!)\n",
    "label_mapping = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "print(\"Label mapping:\", label_mapping)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e7da58b-f3a7-48d1-87a4-b045e4634614",
   "metadata": {},
   "source": [
    "# one hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "282ad7a3-8b14-4c06-b579-9b2400c1b3ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             title                                               text  \\\n",
      "0  Breaking News 1  This is the content of article 1. It contains ...   \n",
      "1  Breaking News 2  This is the content of article 2. It contains ...   \n",
      "2  Breaking News 3  This is the content of article 3. It contains ...   \n",
      "3  Breaking News 4  This is the content of article 4. It contains ...   \n",
      "4  Breaking News 5  This is the content of article 5. It contains ...   \n",
      "\n",
      "   sentiment_score  word_count  has_images  has_videos  readability_score  \\\n",
      "0            -0.22        1302           0           0              66.18   \n",
      "1             0.92         322           1           0              41.10   \n",
      "2             0.25         228           0           1              30.04   \n",
      "3             0.94         155           1           0              75.16   \n",
      "4            -0.01         962           1           0              43.90   \n",
      "\n",
      "   num_shares  num_comments political_bias  ...  category_Entertainment  \\\n",
      "0       47305           450         Center  ...                     1.0   \n",
      "1       39804           530           Left  ...                     0.0   \n",
      "2       45860           763         Center  ...                     0.0   \n",
      "3       34222           945         Center  ...                     0.0   \n",
      "4       35934           433          Right  ...                     0.0   \n",
      "\n",
      "   category_Health  category_Politics  category_Sports  category_Technology  \\\n",
      "0              0.0                0.0              0.0                  0.0   \n",
      "1              0.0                0.0              0.0                  1.0   \n",
      "2              0.0                0.0              1.0                  0.0   \n",
      "3              0.0                0.0              1.0                  0.0   \n",
      "4              0.0                0.0              0.0                  1.0   \n",
      "\n",
      "   fact_check_rating_FALSE  fact_check_rating_Mixed  fact_check_rating_TRUE  \\\n",
      "0                      1.0                      0.0                     0.0   \n",
      "1                      0.0                      1.0                     0.0   \n",
      "2                      0.0                      1.0                     0.0   \n",
      "3                      0.0                      0.0                     1.0   \n",
      "4                      0.0                      1.0                     0.0   \n",
      "\n",
      "   is_satirical_0  is_satirical_1  \n",
      "0             0.0             1.0  \n",
      "1             0.0             1.0  \n",
      "2             1.0             0.0  \n",
      "3             0.0             1.0  \n",
      "4             1.0             0.0  \n",
      "\n",
      "[5 rows x 46 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import pandas as pd\n",
    "\n",
    "# Columns for One-Hot Encoding\n",
    "one_hot_columns = [\"state\", \"category\", \"fact_check_rating\", \"is_satirical\"]\n",
    "\n",
    "# Initialize encoder\n",
    "ohe = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "\n",
    "# Fit + transform\n",
    "encoded_array = ohe.fit_transform(df[one_hot_columns])\n",
    "\n",
    "# Convert encoded data to a DataFrame\n",
    "encoded_df = pd.DataFrame(encoded_array, columns=ohe.get_feature_names_out(one_hot_columns))\n",
    "\n",
    "# Combine original data with encoded\n",
    "df_ohe = pd.concat([df.drop(columns=one_hot_columns), encoded_df], axis=1)\n",
    "\n",
    "print(df_ohe.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c909bcb-50dc-4d95-96ea-3df5c5d0e424",
   "metadata": {},
   "source": [
    "# Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "57654d07-8e46-47da-951e-61b419061580",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Mapping: {np.int64(0): np.int64(0), np.int64(1): np.int64(1)}\n",
      "Final X shape: (4000, 4046)\n",
      "X_train: (3200, 4046) y_train: (3200,)\n",
      "X_test: (800, 4046) y_test: (800,)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# -----------------------------\n",
    "# 1) Define columns\n",
    "# -----------------------------\n",
    "text_column = \"text\"\n",
    "target_column = \"label\"\n",
    "\n",
    "one_hot_columns = [\"state\", \"category\", \"fact_check_rating\", \"is_satirical\"]\n",
    "ordinal_columns = [\"sentiment_score\", \"political_bias\", \"source_reputation\", \"clickbait_score\"]\n",
    "numeric_columns = [\"word_count\", \"has_images\", \"has_videos\", \"readability_score\",\n",
    "                   \"num_shares\", \"num_comments\", \"trust_score\", \"plagiarism_score\"]\n",
    "\n",
    "# -----------------------------\n",
    "# 2) Encode target column\n",
    "# -----------------------------\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(df[target_column])\n",
    "print(\"Label Mapping:\", dict(zip(le.classes_, le.transform(le.classes_))))\n",
    "\n",
    "# -----------------------------\n",
    "# 3) Text vectorization\n",
    "# -----------------------------\n",
    "cv = CountVectorizer(max_features=5000)\n",
    "X_text = cv.fit_transform(df[text_column]).toarray()\n",
    "\n",
    "# -----------------------------\n",
    "# 4) One-Hot Encoding\n",
    "# -----------------------------\n",
    "ohe = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "X_ohe = ohe.fit_transform(df[one_hot_columns])\n",
    "\n",
    "# -----------------------------\n",
    "# 5) Ordinal Encoding\n",
    "# -----------------------------\n",
    "# Map ordinal manually (example)\n",
    "sentiment_map = {\"Negative\":0, \"Neutral\":1, \"Positive\":2}\n",
    "political_map = {\"Left\":0, \"Center\":1, \"Right\":2}\n",
    "reputation_map = {\"Low\":0, \"Medium\":1, \"High\":2}\n",
    "clickbait_map = {1:0, 2:1, 3:2, 4:3, 5:4}  # adjust if needed\n",
    "\n",
    "df_ordinal = df[ordinal_columns].copy()\n",
    "df_ordinal[\"sentiment_score\"] = df_ordinal[\"sentiment_score\"].map(sentiment_map)\n",
    "df_ordinal[\"political_bias\"] = df_ordinal[\"political_bias\"].map(political_map)\n",
    "df_ordinal[\"source_reputation\"] = df_ordinal[\"source_reputation\"].map(reputation_map)\n",
    "df_ordinal[\"clickbait_score\"] = df_ordinal[\"clickbait_score\"].map(clickbait_map)\n",
    "\n",
    "X_ordinal = df_ordinal.values\n",
    "\n",
    "# -----------------------------\n",
    "# 6) Numeric features\n",
    "# -----------------------------\n",
    "X_numeric = df[numeric_columns].values\n",
    "\n",
    "# -----------------------------\n",
    "# 7) Combine all features\n",
    "# -----------------------------\n",
    "import numpy as np\n",
    "X = np.concatenate([X_text, X_ohe, X_ordinal, X_numeric], axis=1)\n",
    "print(\"Final X shape:\", X.shape)\n",
    "\n",
    "# -----------------------------\n",
    "# 8) Train-Test Split\n",
    "# -----------------------------\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(\"X_train:\", X_train.shape, \"y_train:\", y_train.shape)\n",
    "print(\"X_test:\", X_test.shape, \"y_test:\", y_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "481b1490-d352-46d9-bbd3-d8fb8df94946",
   "metadata": {},
   "source": [
    "# Model Training (Logistic Regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "51bb935f-ce76-4dda-8d42-491a1a1078bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anconda\\envs\\fakenews_detection\\lib\\site-packages\\sklearn\\impute\\_base.py:653: UserWarning: Skipping features without any observed values: [4034 4036]. At least one non-missing value is needed for imputation with strategy='mean'.\n",
      "  warnings.warn(\n",
      "D:\\anconda\\envs\\fakenews_detection\\lib\\site-packages\\sklearn\\impute\\_base.py:653: UserWarning: Skipping features without any observed values: [4034 4036]. At least one non-missing value is needed for imputation with strategy='mean'.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 56.62%\n",
      "Test Accuracy: 48.12%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anconda\\envs\\fakenews_detection\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Fill any remaining NaN in X with mean\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_train = imputer.fit_transform(X_train)\n",
    "X_test = imputer.transform(X_test)\n",
    "\n",
    "# Now train Logistic Regression\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate\n",
    "train_acc = model.score(X_train, y_train)\n",
    "test_acc = model.score(X_test, y_test)\n",
    "print(f\"Train Accuracy: {train_acc*100:.2f}%\")\n",
    "print(f\"Test Accuracy: {test_acc*100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "868d60d7-6e1d-4c77-ba50-72004ecbc641",
   "metadata": {},
   "source": [
    "# Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5a250014-8443-4073-bb21-01323b0fbdb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45893156-331f-488a-80ef-feaf043ea165",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2134d4b2-d029-4942-be1b-e69ba59880ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.48125\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.49      0.49       405\n",
      "           1       0.47      0.47      0.47       395\n",
      "\n",
      "    accuracy                           0.48       800\n",
      "   macro avg       0.48      0.48      0.48       800\n",
      "weighted avg       0.48      0.48      0.48       800\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ba32ee3e-a369-4d2d-890b-aa3f3819d5f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    2026\n",
       "1    1974\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05674662-5931-4d85-bb11-ef0738e7fd1d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
